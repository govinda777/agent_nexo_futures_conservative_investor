## üìö Agent

A **rede neural** do agente √© composta por **tr√™s m√≥dulos principais**:

### üß† Arquitetura da Rede Neural
1. **M√≥dulo de Entrada**: Processa os dados do mercado, incluindo pre√ßos, volume e volatilidade.
2. **M√≥dulo de Processamento**: Usa **Transformers** para detectar padr√µes em s√©ries temporais e redes neurais profundas (**DNN**) para refinar a an√°lise dos dados.
3. **M√≥dulo de Decis√£o**: Implementa **Aprendizado por Refor√ßo Profundo (PPO - Proximal Policy Optimization)** para ajustar automaticamente a estrat√©gia de trading.

### üîÑ Fluxo de Treinamento
1. **Coleta de dados** üìä: Obt√©m pre√ßos do BTC, volume de negocia√ß√£o e outras informa√ß√µes do mercado.
2. **Pr√©-processamento** üîç: Filtra dados e remove informa√ß√µes irrelevantes.
3. **Treinamento supervisionado** üéì: Aprende padr√µes de comportamento a partir de dados passados.
4. **Treinamento por Refor√ßo (PPO)** üèÜ: Testa diferentes estrat√©gias e aprende quais funcionam melhor.
5. **Backtesting** üîÑ: Simula opera√ß√µes para ver como o modelo se sairia em diferentes cen√°rios.
6. **Ajustes cont√≠nuos** üìà: O agente melhora ao longo do tempo, adaptando-se ao mercado.

### üìä Diagrama Detalhado da Rede Neural
```mermaid
flowchart TD
    subgraph Inputs de Mercado
        M1(Pre√ßos & Volume em Tempo Real)
        M2(Indicadores T√©cnicos / Volatilidade)
        M3(Not√≠cias & Sentimento)
    end

    subgraph Rede Neural + RL
        R1(Transformers / LSTM / CNN)
        R2(Camadas Densas - DNN)
        R3(Pol√≠tica PPO - Aprendizado por Refor√ßo)
    end

    subgraph Decis√£o & A√ß√£o
        D1(Calcula Sinal: Comprar, Vender, Manter)
        D2(Ajusta Stop Loss/Take Profit)
    end

    subgraph Circuit Breaker
        CB1(Monitor de Perdas Seguidas / Drawdown)
        CB2(Ativa Bloqueio se Limite Atingido?)
        CB3(Pausa e Reavalia√ß√£o)
    end

    subgraph Execu√ß√£o
        E1(Envio de Ordem - API Nexo)
        E2(Monitoramento Posi√ß√£o)
        E3(Retorno: Lucro/Perda)
    end

    subgraph Feedback
        F1(Recompensa/Penalidade)
        F2(Atualiza√ß√£o da Pol√≠tica PPO)
    end

    M1 --> R1
    M2 --> R1
    M3 --> R1

    R1 --> R2
    R2 --> R3
    R3 --> D1
    R3 --> D2

    D1 --> CB1
    CB1 --> CB2
    CB2 -->|Se ativado| CB3
    CB3 -->|Pausa Opera√ß√µes| D1

    D1 --> E1
    D2 --> E1
    E1 --> E2
    E2 --> E3
    E3 --> F1
    F1 --> F2
    F2 --> R3

```

```mermaid
graph TD;
    A[Entrada: Dados do Mercado] -->|Pre√ßos, Volume, Volatilidade| B[Pr√©-processamento]
    B -->|Normaliza√ß√£o de Dados| C[Transformers para S√©ries Temporais]
    C -->|Padr√µes Identificados| D[Camadas Neurais Densas DNN]
    D -->|Decis√£o Inicial| E[Pol√≠tica de A√ß√£o PPO]
    E -->|Compra/Venda/Manuten√ß√£o| F[Execu√ß√£o de Ordem]
    E -->|Ajuste Autom√°tico de Stop Loss| G[Ajuste de Risco]
    F -->|Feedback para Aprendizado| H[Recompensa/Penaliza√ß√£o]
    H -->|Melhoria Cont√≠nua| I[Aprendizado por Refor√ßo]
```

---

# üìà Training Scenarios for Agente Nexo

## üèÜ Objetivo
Este documento define diferentes **cen√°rios de treinamento** para o agente Nexo, permitindo que ele aprenda a tomar **decis√µes de investimento** da melhor forma poss√≠vel em **diferentes condi√ß√µes de mercado**.

O treinamento ser√° dividido em **jogos/simula√ß√µes**, onde o agente enfrentar√° desafios e aprender√° **estrat√©gias vencedoras**.

---

## üéÆ Jogos e Cen√°rios de Treinamento

### **1Ô∏è‚É£ Jogo: Mercado de Baixa Extrema (Bear Market)**
üîπ **Objetivo:** Ensinar o agente a **evitar perdas** e identificar pontos de entrada seguros.
üîπ **Cen√°rio:**
   - O mercado cai 10% em um curto per√≠odo.
   - O agente precisa decidir se **mant√©m a posi√ß√£o, vende ou espera**.
   - Se ele vender muito cedo, pode perder um poss√≠vel repique.
   - Se ele segurar muito tempo, pode sofrer grandes perdas.
üîπ **Recompensa:**
   - Se evitar perdas acima de 5% e encontrar um **ponto de entrada lucrativo**, recebe uma **recompensa alta**.
   - Se segurar demais e n√£o conseguir recuperar, recebe **penaliza√ß√£o**.

### **2Ô∏è‚É£ Jogo: Mercado Lateral (Consolida√ß√£o)**
üîπ **Objetivo:** Ensinar o agente a operar em **mercados sem tend√™ncia**.
üîπ **Cen√°rio:**
   - O pre√ßo oscila entre 40.000 e 42.000 USDT.
   - O agente deve aprender a **comprar na parte inferior e vender na parte superior**.
   - Se ele operar fora dessas faixas, pode sofrer **preju√≠zos desnecess√°rios**.
üîπ **Recompensa:**
   - Se fizer **entradas e sa√≠das precisas dentro da faixa**, recebe **recompensa alta**.
   - Se comprar ou vender nos momentos errados, recebe **penaliza√ß√£o**.

### **3Ô∏è‚É£ Jogo: Pump & Dump (Volatilidade Extrema)**
üîπ **Objetivo:** Ensinar o agente a **evitar armadilhas e capturar movimentos r√°pidos**.
üîπ **Cen√°rio:**
   - O mercado sobe rapidamente 15% e depois cai 20%.
   - O agente precisa decidir **se entra na alta ou espera uma corre√ß√£o**.
üîπ **Recompensa:**
   - Se identificar corretamente um **ponto de entrada seguro**, recebe **recompensa**.
   - Se entrar muito tarde e sofrer perdas com a corre√ß√£o, recebe **penaliza√ß√£o**.

### **4Ô∏è‚É£ Jogo: Not√≠cias Impactantes**
üîπ **Objetivo:** Ensinar o agente a **adaptar-se a eventos inesperados**.
üîπ **Cen√°rio:**
   - Uma **not√≠cia impactante** surge, alterando o sentimento do mercado.
   - O agente deve identificar se a not√≠cia **gera uma nova tend√™ncia ou apenas ru√≠do**.
üîπ **Recompensa:**
   - Se ajustar sua estrat√©gia corretamente de acordo com a **not√≠cia**, recebe **recompensa alta**.
   - Se entrar cedo demais ou ignorar o impacto real, recebe **penaliza√ß√£o**.

### **5Ô∏è‚É£ Jogo: Flash Crash (Queda R√°pida e Recupera√ß√£o)**
üîπ **Objetivo:** Ensinar o agente a **reagir rapidamente e identificar oportunidades**.
üîπ **Cen√°rio:**
   - O BTC despenca 10% em minutos, mas recupera 8% logo depois.
   - O agente precisa aprender a **n√£o vender no p√¢nico** e procurar oportunidades de compra.
üîπ **Recompensa:**
   - Se conseguir **comprar no momento certo**, recebe **recompensa alta**.
   - Se vender no fundo por medo, recebe **penaliza√ß√£o**.

---

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ        SISTEMA DE MEDALHAS BASEADO EM LUCRO E M√âTRICAS DE PERFORMANCE  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

A ideia √© que as **medalhas** sejam concedidas aos indiv√≠duos (modelos) que conseguem se **manter lucrativos** ao longo dos cen√°rios de teste, mas tamb√©m respeitando m√©tricas adicionais de **risco** e **consist√™ncia**. Abaixo, apresento um esquema mais detalhado para integrar **lucro**, **drawdown**, **taxa de acerto** e outras estat√≠sticas.

## 1. Pontua√ß√£o Geral (Score)

Para que cada indiv√≠duo seja avaliado de forma **objetiva**, podemos criar um **Score Global** que agregue v√°rios indicadores. Por exemplo:

1. **Lucro Acumulado** (Profit Factor)
   - Mede o total de lucro (ou preju√≠zo) ao final dos cen√°rios de teste.
   - Ex.: Se o modelo terminou com +15% sobre o capital inicial, recebe uma pontua√ß√£o proporcional.

2. **Stability Score** (Drawdown e Volatilidade)
   - Penaliza modelos que geram picos de perda (max drawdown) ou t√™m comportamento muito vol√°til.
   - Ex.: Se o max drawdown for menor que 15%, recebe um b√¥nus na pontua√ß√£o final.

3. **Consist√™ncia de Retornos** (Sharpe ou Sortino Ratio)
   - Avalia se o modelo gera um **retorno est√°vel**, ajustado ao risco.
   - Ex.: Quanto maior o Sharpe/Sortino Ratio, maior a pontua√ß√£o.

4. **Taxa de Acerto** / **Taxa de Opera√ß√µes Lucrativas**
   - Mede quantos trades terminaram no lucro em rela√ß√£o ao total.
   - Mesmo com bom lucro, se a taxa de acerto for muito baixa, a pontua√ß√£o final cai.

5. **Performance em M√∫ltiplos Cen√°rios** (Bear, Lateral, Pump & Dump, etc.)
   - Verifica se o indiv√≠duo **n√£o ‚Äúbamba‚Äù** em algum cen√°rio.  
   - Modelos que conseguem manter a **lucratividade** em todos os cen√°rios recebem pontua√ß√£o adicional.

> **F√≥rmula gen√©rica**:  
> \[
> \text{Score Global} = w_1 \times \text{Lucro} \;+\; w_2 \times \text{Estabilidade} \;+\; w_3 \times \text{Consist√™ncia} \;+\; w_4 \times \text{Taxa de Acerto} \;+\; w_5 \times \text{MultiCen√°rios}
> \]  
> Onde \(w_i\) s√£o pesos que voc√™ define para cada indicador, priorizando a ‚Äúfilosofia‚Äù do projeto (ex.: conservador ‚Üí peso maior em estabilidade e drawdown).

---

## 2. Regras B√°sicas para Ganhar Medalha

- **Regra Geral**: O modelo **deve** terminar os cen√°rios **lucrativo** (lucro >= 0) para ser eleg√≠vel a qualquer medalha.  
- **Restri√ß√µes de Seguran√ßa**:  
  - Se o drawdown excede 30%, o modelo fica **desclassificado** de premia√ß√µes altas (apenas recebe ‚Äúbronze‚Äù ou nenhuma).  
  - Se a taxa de acerto for muito baixa (ex.: < 40%), tamb√©m n√£o passa de ‚Äúbronze‚Äù ou ‚Äúsem medalha‚Äù.  

**Pontua√ß√£o Final** ‚Üí **Medalha**:
- **Ouro**: Score Global >= 80 + lucros positivos em todos os cen√°rios.  
- **Prata**: Score Global entre 65 e 79 + n√£o teve drawdown > 25%.  
- **Bronze**: Score Global entre 50 e 64 + n√£o teve drawdown > 30%.  
- **Sem Medalha**: Abaixo de 50 pontos ou lucro negativo.

*(Obs.: Os n√∫meros acima s√£o exemplos, adapte conforme sua an√°lise e amplitude de valores.)*

---

## 3. Poss√≠vel Exemplo de C√°lculo

**Exemplo** de como pontuar um modelo ao final dos ‚Äújogos‚Äù:

| Indicador                | Valor Exemplo   | Convers√£o em Pontos   |
|--------------------------|-----------------|------------------------|
| Lucro Total             | +12%            | +30 pontos            |
| Drawdown M√°ximo         | 18%             | +20 pontos (pequena penalidade) |
| Sharpe Ratio            | 1.8             | +20 pontos            |
| Taxa de Acerto Geral    | 58%             | +10 pontos            |
| Cen√°rios Sem Perdas     | 4 de 5          | +10 pontos            |

> **Score Global** = 30 + 20 + 20 + 10 + 10 = **90** ‚Üí **Medalha de Ouro**  
> (Pois foi lucrativo e pontuou acima de 80.)

Outro modelo, com 8% de lucro, 25% drawdown e Sharpe 1.2, pode ter:
- Lucro +25 pontos  
- Drawdown 25% +10 pontos  
- Sharpe 1.2 +15 pontos  
- Acerto 50% +5 pontos  
- Cen√°rios sem perdas 3/5 +5 pontos  
**Score = 25+10+15+5+5= 60** ‚Üí **Medalha de Bronze** (exemplo de corte).

---

## 4. Gamifica√ß√£o com Medalhas Especiais

Al√©m das medalhas principais (Ouro/Prata/Bronze), voc√™ pode ter **conquistas extras** relacionadas especificamente ao **lucro** em cada cen√°rio, por exemplo:

1. **‚ÄúInvestidor de A√ßo‚Äù**  
   - Quando o modelo mant√©m **lucro positivo** mesmo em Bear Market severo, sem drawdown acima de 20%.

2. **‚ÄúSniper de Volatilidade‚Äù**  
   - Quando captura lucros acima de x% em cen√°rios de **Pump & Dump**, entrando e saindo ‚Äúno ponto‚Äù.

3. **‚ÄúBlindado contra Flash Crash‚Äù**  
   - Zero posi√ß√µes liquidadas durante um flash crash, mantendo-se ainda no verde (lucro >= 0).

Essas medalhas especiais **incentivam** a excel√™ncia em aspectos espec√≠ficos do mercado.

---

## 5. Resumo e Conclus√£o

Com esse **sistema de medalhas** orientado a **lucratividade e m√©tricas de risco**, voc√™:

1. **Garante** que apenas indiv√≠duos efetivamente lucrativos recebam medalhas.  
2. **Premia** a consist√™ncia e estabilidade, alinhada ao foco conservador.  
3. **Adota** um Score Global que equilibra m√∫ltiplos indicadores (lucro, drawdown, Sharpe, taxa de acerto).  
4. **Gamifica** o aprendizado, criando um ranking onde cada modelo (indiv√≠duo) busca pontuar o m√°ximo poss√≠vel nos cen√°rios de simula√ß√£o.

---

## üß† Como o Agente Aprende a Melhor Estrat√©gia?

1. **Simula√ß√µes Massivas**
   - O agente √© testado **milhares de vezes** em cada cen√°rio.
   - Cada simula√ß√£o ajusta os pesos da rede neural para **evitar erros futuros**.

2. **Recompensa por Decis√µes Certas**
   - O modelo de aprendizado por refor√ßo **recompensa boas decis√µes** e **penaliza erros**.
   - Cada jogo refor√ßa **padr√µes de comportamento eficiente**.

3. **Ajustes Cont√≠nuos**
   - Ap√≥s o treinamento inicial, o agente continua aprendendo **com o mercado ao vivo**.
   - Se um novo padr√£o de mercado surgir, o agente pode **se adaptar automaticamente**.

---

üöÄ **Com esses jogos de treinamento, o agente poder√° operar de forma mais inteligente e segura no mercado de futuros BTC/USDT!**

